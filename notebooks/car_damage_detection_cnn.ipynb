{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cvV5ajkEF2cm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, efficientnet_b0\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDamageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None, damage_areas=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.damage_areas = damage_areas if damage_areas is not None else [0] * len(image_paths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        damage_area = self.damage_areas[idx]\n",
        "\n",
        "        return image, label, damage_area\n"
      ],
      "metadata": {
        "id": "rls2dep8GCCd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDamageCNN(nn.Module):\n",
        "    def __init__(self, num_classes=8, pretrained=True):\n",
        "        super(CarDamageCNN, self).__init__()\n",
        "\n",
        "        # Use EfficientNet as backbone (good for small datasets)\n",
        "        self.backbone = efficientnet_b0(pretrained=pretrained)\n",
        "\n",
        "        # Get the number of features from the backbone\n",
        "        # Access the in_features from the last layer before the classifier\n",
        "        # The classifier is a Sequential with the last layer being Linear\n",
        "        num_features = self.backbone.classifier[-1].in_features\n",
        "\n",
        "\n",
        "        # Replace classifier with our custom layers\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "        # Additional regression head for damage area estimation\n",
        "        self.area_regressor = nn.Sequential(\n",
        "            nn.Linear(num_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features\n",
        "        features = self.backbone.features(x)\n",
        "        features = self.backbone.avgpool(features)\n",
        "        features = torch.flatten(features, 1)\n",
        "\n",
        "        # Classification output\n",
        "        classification = self.backbone.classifier(features)\n",
        "\n",
        "        # Regression output for damage area\n",
        "        area_pred = self.area_regressor(features)\n",
        "\n",
        "        return classification, area_pred"
      ],
      "metadata": {
        "id": "t2upWrx2H96f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDamageDetector:\n",
        "    def __init__(self, model_path: Optional[str] = None):\n",
        "        self.damage_classes = [\n",
        "            'no_damage', 'dent', 'scratch', 'crack',\n",
        "            'broken_part', 'rust', 'paint_damage', 'severe_damage'\n",
        "        ]\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = CarDamageCNN(num_classes=len(self.damage_classes))\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Label encoder for damage classes\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(self.damage_classes)\n",
        "\n",
        "        # Price prediction model\n",
        "        self.price_model = None\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "        # Data transformations\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.val_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Price estimation based on damage type and severity\n",
        "        self.base_prices = {\n",
        "            'no_damage': 0,\n",
        "            'dent': 300,\n",
        "            'scratch': 200,\n",
        "            'crack': 400,\n",
        "            'broken_part': 800,\n",
        "            'rust': 150,\n",
        "            'paint_damage': 350,\n",
        "            'severe_damage': 1200\n",
        "        }\n",
        "\n",
        "        # Load model if path provided\n",
        "        if model_path and os.path.exists(model_path):\n",
        "            self.load_model(model_path)"
      ],
      "metadata": {
        "id": "GPO21MS3IE5V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(self, data_dir: str, create_labels: bool = False) -> Tuple[List, List, List]:\n",
        "        \"\"\"\n",
        "        Prepare dataset from directory structure or CSV file\n",
        "        \"\"\"\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "        damage_areas = []\n",
        "\n",
        "        if create_labels:\n",
        "            # Interactive labeling for small dataset\n",
        "            print(\"Interactive labeling mode...\")\n",
        "            self._interactive_labeling(data_dir)\n",
        "\n",
        "        # Load from CSV if exists\n",
        "        csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "        if os.path.exists(csv_path):\n",
        "            df = pd.read_csv(csv_path)\n",
        "            image_paths = [os.path.join(data_dir, img) for img in df['image_path']]\n",
        "            labels = df['damage_type'].tolist()\n",
        "            damage_areas = df.get('damage_area', [0] * len(image_paths)).tolist()\n",
        "        else:\n",
        "            # Assume directory structure: data_dir/damage_type/image.jpg\n",
        "            for damage_type in os.listdir(data_dir):\n",
        "                damage_dir = os.path.join(data_dir, damage_type)\n",
        "                if os.path.isdir(damage_dir):\n",
        "                    for img_file in os.listdir(damage_dir):\n",
        "                        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                            image_paths.append(os.path.join(damage_dir, img_file))\n",
        "                            labels.append(damage_type)\n",
        "                            damage_areas.append(0)  # Default area\n",
        "\n",
        "        print(f\"Found {len(image_paths)} images\")\n",
        "        print(f\"Label distribution: {Counter(labels)}\")\n",
        "\n",
        "        return image_paths, labels, damage_areas"
      ],
      "metadata": {
        "id": "9kfo-oVUIJCH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _interactive_labeling(self, data_dir: str):\n",
        "        labels_data = []\n",
        "\n",
        "        for img_file in os.listdir(data_dir):\n",
        "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(data_dir, img_file)\n",
        "\n",
        "                # Display image\n",
        "                img = cv2.imread(img_path)\n",
        "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                plt.imshow(img_rgb)\n",
        "                plt.title(f\"Label this image: {img_file}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "                # Get label\n",
        "                print(\"\\nDamage types:\")\n",
        "                for i, damage_type in enumerate(self.damage_classes):\n",
        "                    print(f\"{i}: {damage_type}\")\n",
        "\n",
        "                while True:\n",
        "                    try:\n",
        "                        label_idx = int(input(\"Enter damage type index: \"))\n",
        "                        if 0 <= label_idx < len(self.damage_classes):\n",
        "                            damage_type = self.damage_classes[label_idx]\n",
        "                            break\n",
        "                        else:\n",
        "                            print(\"Invalid index. Try again.\")\n",
        "                    except ValueError:\n",
        "                        print(\"Please enter a valid number.\")\n",
        "\n",
        "                # Get damage area estimate (optional)\n",
        "                try:\n",
        "                    area = float(input(\"Estimated damage area (0-1, where 1 is entire image): \") or \"0\")\n",
        "                except ValueError:\n",
        "                    area = 0\n",
        "\n",
        "                labels_data.append({\n",
        "                    'image_path': img_file,\n",
        "                    'damage_type': damage_type,\n",
        "                    'damage_area': area\n",
        "                })\n",
        "\n",
        "                plt.close()\n",
        "\n",
        "        # Save labels\n",
        "        df = pd.DataFrame(labels_data)\n",
        "        df.to_csv(os.path.join(data_dir, 'labels.csv'), index=False)\n",
        "        print(f\"Labels saved to {os.path.join(data_dir, 'labels.csv')}\")"
      ],
      "metadata": {
        "id": "voWJqU8zIMC4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDamageDetector:\n",
        "    def __init__(self, model_path: Optional[str] = None):\n",
        "        self.damage_classes = [\n",
        "            'no_damage', 'dent', 'scratch', 'crack',\n",
        "            'broken_part', 'rust', 'paint_damage', 'severe_damage'\n",
        "        ]\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = CarDamageCNN(num_classes=len(self.damage_classes))\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Label encoder for damage classes\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(self.damage_classes)\n",
        "\n",
        "        # Price prediction model\n",
        "        self.price_model = None\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "        # Data transformations\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.val_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Price estimation based on damage type and severity\n",
        "        self.base_prices = {\n",
        "            'no_damage': 0,\n",
        "            'dent': 300,\n",
        "            'scratch': 200,\n",
        "            'crack': 400,\n",
        "            'broken_part': 800,\n",
        "            'rust': 150,\n",
        "            'paint_damage': 350,\n",
        "            'severe_damage': 1200\n",
        "        }\n",
        "\n",
        "        # Load model if path provided\n",
        "        if model_path and os.path.exists(model_path):\n",
        "            self.load_model(model_path)\n",
        "\n",
        "    def prepare_dataset(self, data_dir: str, create_labels: bool = False) -> Tuple[List, List, List]:\n",
        "        \"\"\"\n",
        "        Prepare dataset from directory structure or CSV file\n",
        "        \"\"\"\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "        damage_areas = []\n",
        "\n",
        "        csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            # Load from CSV if exists\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "                if not df.empty:\n",
        "                    image_paths = [os.path.join(data_dir, img) for img in df['image_path']]\n",
        "                    labels = df['damage_type'].tolist()\n",
        "                    damage_areas = df.get('damage_area', [0] * len(image_paths)).tolist()\n",
        "                else:\n",
        "                    print(f\"Warning: {csv_path} is empty.\")\n",
        "            except pd.errors.EmptyDataError:\n",
        "                print(f\"Warning: {csv_path} is empty or has no columns.\")\n",
        "        elif create_labels:\n",
        "            # Interactive labeling if no CSV and create_labels is True\n",
        "            print(\"Interactive labeling mode...\")\n",
        "            self._interactive_labeling(data_dir)\n",
        "            # After interactive labeling, load the created CSV\n",
        "            if os.path.exists(csv_path):\n",
        "                 try:\n",
        "                    df = pd.read_csv(csv_path)\n",
        "                    if not df.empty:\n",
        "                        image_paths = [os.path.join(data_dir, img) for img in df['image_path']]\n",
        "                        labels = df['damage_type'].tolist()\n",
        "                        damage_areas = df.get('damage_area', [0] * len(image_paths)).tolist()\n",
        "                    else:\n",
        "                        print(f\"Warning: {csv_path} is empty after interactive labeling.\")\n",
        "                 except pd.errors.EmptyDataError:\n",
        "                    print(f\"Warning: {csv_path} is empty or has no columns after interactive labeling.\")\n",
        "            else:\n",
        "                print(f\"Warning: {csv_path} was not created during interactive labeling.\")\n",
        "\n",
        "        else:\n",
        "            # Assume directory structure: data_dir/damage_type/image.jpg\n",
        "            # Or images are directly in data_dir without subdirectories\n",
        "            for item in os.listdir(data_dir):\n",
        "                item_path = os.path.join(data_dir, item)\n",
        "                if os.path.isdir(item_path):\n",
        "                    # Process as directory structure\n",
        "                    for img_file in os.listdir(item_path):\n",
        "                        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                            image_paths.append(os.path.join(item_path, img_file))\n",
        "                            labels.append(item)\n",
        "                            damage_areas.append(0)  # Default area\n",
        "                elif os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                     # Process as images directly in data_dir (requires labeling)\n",
        "                     # In this case, the user needs to provide labels via CSV or interactive labeling\n",
        "                     # This part of the logic should ideally not be reached if create_labels is True\n",
        "                     # or if a CSV exists. If reached, it means unlabeled images exist.\n",
        "                     print(f\"Warning: Found unlabeled image {item_path}. Please provide labels via CSV or set create_labels=True for interactive labeling.\")\n",
        "                     pass # Or raise an error, or add to a list of unlabeled images\n",
        "\n",
        "\n",
        "        print(f\"Found {len(image_paths)} images\")\n",
        "        print(f\"Label distribution: {Counter(labels)}\")\n",
        "\n",
        "        return image_paths, labels, damage_areas\n",
        "\n",
        "    def _interactive_labeling(self, data_dir: str):\n",
        "        labels_data = []\n",
        "        image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"No image files found in {data_dir} for interactive labeling.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Found {len(image_files)} images for interactive labeling.\")\n",
        "\n",
        "        for img_file in image_files:\n",
        "            img_path = os.path.join(data_dir, img_file)\n",
        "\n",
        "            # Display image\n",
        "            img = cv2.imread(img_path)\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.imshow(img_rgb)\n",
        "            plt.title(f\"Label this image: {img_file}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            # Get label\n",
        "            print(\"\\nDamage types:\")\n",
        "            for i, damage_type in enumerate(self.damage_classes):\n",
        "                print(f\"{i}: {damage_type}\")\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    label_idx = int(input(\"Enter damage type index: \"))\n",
        "                    if 0 <= label_idx < len(self.damage_classes):\n",
        "                        damage_type = self.damage_classes[label_idx]\n",
        "                        break\n",
        "                    else:\n",
        "                        print(\"Invalid index. Try again.\")\n",
        "                except ValueError:\n",
        "                    print(\"Please enter a valid number.\")\n",
        "\n",
        "            # Get damage area estimate (optional)\n",
        "            try:\n",
        "                area = float(input(\"Estimated damage area (0-1, where 1 is entire image): \") or \"0\")\n",
        "            except ValueError:\n",
        "                area = 0\n",
        "\n",
        "            labels_data.append({\n",
        "                'image_path': img_file,\n",
        "                'damage_type': damage_type,\n",
        "                'damage_area': area\n",
        "            })\n",
        "\n",
        "            plt.close()\n",
        "\n",
        "        # Save labels\n",
        "        if labels_data:\n",
        "            df = pd.DataFrame(labels_data)\n",
        "            df.to_csv(os.path.join(data_dir, 'labels.csv'), index=False)\n",
        "            print(f\"Labels saved to {os.path.join(data_dir, 'labels.csv')}\")\n",
        "        else:\n",
        "            print(\"No labels were collected during interactive labeling. CSV file not created.\")\n",
        "\n",
        "\n",
        "    def train_model(self, data_dir: str, epochs: int = 50, batch_size: int = 8,\n",
        "                   learning_rate: float = 0.001):\n",
        "        # Prepare dataset\n",
        "        image_paths, labels, damage_areas = self.prepare_dataset(data_dir, create_labels=True) # Set create_labels to True here\n",
        "\n",
        "        if not image_paths:\n",
        "            print(\"No images found or labeled. Cannot proceed with training.\")\n",
        "            return\n",
        "\n",
        "        # Encode labels\n",
        "        encoded_labels = self.label_encoder.transform(labels)\n",
        "\n",
        "        # Split data (80-20 split for small dataset)\n",
        "        train_paths, val_paths, train_labels, val_labels, train_areas, val_areas = train_test_split(\n",
        "            image_paths, encoded_labels, damage_areas,\n",
        "            test_size=0.2, random_state=42, stratify=encoded_labels\n",
        "        )\n",
        "\n",
        "        print(f\"Training samples: {len(train_paths)}\")\n",
        "        print(f\"Validation samples: {len(val_paths)}\")\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = CarDamageDataset(train_paths, train_labels,\n",
        "                                       self.train_transform, train_areas)\n",
        "        val_dataset = CarDamageDataset(val_paths, val_labels,\n",
        "                                     self.val_transform, val_areas)\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                shuffle=True, num_workers=2)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                              shuffle=False, num_workers=2)\n",
        "\n",
        "        # Loss functions and optimizer\n",
        "        criterion_cls = nn.CrossEntropyLoss()\n",
        "        criterion_reg = nn.MSELoss()\n",
        "        optimizer = optim.AdamW(self.model.parameters(), lr=learning_rate,\n",
        "                               weight_decay=0.01)\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
        "                                                       patience=5, factor=0.5)\n",
        "\n",
        "        # Training loop\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "\n",
        "            for images, labels, areas in train_loader:\n",
        "                images, labels, areas = images.to(self.device), labels.to(self.device), areas.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                cls_output, area_output = self.model(images)\n",
        "\n",
        "                # Calculate losses\n",
        "                cls_loss = criterion_cls(cls_output, labels)\n",
        "                reg_loss = criterion_reg(area_output.squeeze(), areas.float())\n",
        "\n",
        "                # Combined loss (weighted)\n",
        "                total_loss = cls_loss + 0.1 * reg_loss\n",
        "\n",
        "                total_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += total_loss.item()\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            val_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels, areas in val_loader:\n",
        "                    images, labels, areas = images.to(self.device), labels.to(self.device), areas.to(self.device)\n",
        "\n",
        "                    cls_output, area_output = self.model(images)\n",
        "\n",
        "                    cls_loss = criterion_cls(cls_output, labels)\n",
        "                    reg_loss = criterion_reg(area_output.squeeze(), areas.float())\n",
        "                    total_loss = cls_loss + 0.1 * reg_loss\n",
        "\n",
        "                    val_loss += total_loss.item()\n",
        "\n",
        "                    _, predicted = torch.max(cls_output.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Calculate average losses\n",
        "            train_loss /= len(train_loader)\n",
        "            val_loss /= len(val_loader)\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], '\n",
        "                  f'Train Loss: {train_loss:.4f}, '\n",
        "                  f'Val Loss: {val_loss:.4f}, '\n",
        "                  f'Val Acc: {accuracy:.2f}%')\n",
        "\n",
        "            # Save best model\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                self.save_model('best_car_damage_model.pth')\n",
        "\n",
        "        # Plot training curves\n",
        "        self._plot_training_curves(train_losses, val_losses)\n",
        "\n",
        "        # Load best model\n",
        "        self.load_model('best_car_damage_model.pth')\n",
        "\n",
        "        print(f\"Training completed. Best validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    def _plot_training_curves(self, train_losses: List, val_losses: List):\n",
        "        \"\"\"\n",
        "        Plot training and validation loss curves\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def predict_damage(self, image_path: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Predict damage type and area for a single image\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = self.val_transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            cls_output, area_output = self.model(image_tensor)\n",
        "\n",
        "            # Get prediction probabilities\n",
        "            probabilities = torch.softmax(cls_output, dim=1)\n",
        "            confidence, predicted_class = torch.max(probabilities, 1)\n",
        "\n",
        "            # Get damage area prediction\n",
        "            predicted_area = area_output.item()\n",
        "\n",
        "        # Decode prediction\n",
        "        damage_type = self.label_encoder.inverse_transform([predicted_class.item()])[0]\n",
        "        confidence_score = confidence.item()\n",
        "\n",
        "        # Get all class probabilities\n",
        "        all_probabilities = probabilities.cpu().numpy()[0]\n",
        "        class_probabilities = {}\n",
        "        for i, class_name in enumerate(self.damage_classes):\n",
        "            class_probabilities[class_name] = float(all_probabilities[i])\n",
        "\n",
        "        return {\n",
        "            'image_path': image_path,\n",
        "            'predicted_damage': damage_type,\n",
        "            'confidence': confidence_score,\n",
        "            'predicted_area': max(0, min(1, predicted_area)),  # Clamp between 0 and 1\n",
        "            'class_probabilities': class_probabilities\n",
        "        }\n",
        "\n",
        "    def estimate_repair_cost(self, prediction_result: Dict,\n",
        "                           car_info: Dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Estimate repair cost based on damage prediction\n",
        "        \"\"\"\n",
        "        damage_type = prediction_result['predicted_damage']\n",
        "        confidence = prediction_result['confidence']\n",
        "        damage_area = prediction_result['predicted_area']\n",
        "\n",
        "        # Base cost\n",
        "        base_cost = self.base_prices.get(damage_type, 0)\n",
        "\n",
        "        # Area multiplier (more damage = higher cost)\n",
        "        area_multiplier = 1 + (damage_area * 2)  # Max 3x multiplier\n",
        "\n",
        "        # Confidence multiplier (lower confidence = higher uncertainty)\n",
        "        confidence_multiplier = 1 + (1 - confidence) * 0.5\n",
        "\n",
        "        # Calculate base repair cost\n",
        "        repair_cost = base_cost * area_multiplier * confidence_multiplier\n",
        "\n",
        "        # Apply car-specific multipliers\n",
        "        if car_info:\n",
        "            # Luxury car multiplier\n",
        "            if car_info.get('luxury_brand', False):\n",
        "                repair_cost *= 1.5\n",
        "\n",
        "            # Age multiplier\n",
        "            age = car_info.get('age', 5)\n",
        "            if age > 10:\n",
        "                repair_cost *= 0.8  # Older cars cheaper to repair\n",
        "            elif age < 3:\n",
        "                repair_cost *= 1.2  # Newer cars more expensive\n",
        "\n",
        "            # Car value multiplier\n",
        "            car_value = car_info.get('value', 15000)\n",
        "            if car_value > 30000:\n",
        "                repair_cost *= 1.3\n",
        "            elif car_value < 10000:\n",
        "                repair_cost *= 0.7\n",
        "\n",
        "        # Calculate confidence interval\n",
        "        uncertainty = 1 - confidence\n",
        "        lower_bound = repair_cost * (1 - uncertainty * 0.3)\n",
        "        upper_bound = repair_cost * (1 + uncertainty * 0.3)\n",
        "\n",
        "        return {\n",
        "            'estimated_cost': float(repair_cost),\n",
        "            'confidence_interval': (float(lower_bound), float(upper_bound)),\n",
        "            'cost_factors': {\n",
        "                'base_cost': float(base_cost),\n",
        "                'area_multiplier': float(area_multiplier),\n",
        "                'confidence_multiplier': float(confidence_multiplier),\n",
        "                'damage_area': float(damage_area)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def process_image(self, image_path: str, car_info: Dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Complete pipeline: predict damage and estimate cost\n",
        "        \"\"\"\n",
        "        # Predict damage\n",
        "        damage_result = self.predict_damage(image_path)\n",
        "\n",
        "        # Estimate cost\n",
        "        cost_result = self.estimate_repair_cost(damage_result, car_info)\n",
        "\n",
        "        # Combine results\n",
        "        complete_result = {\n",
        "            **damage_result,\n",
        "            **cost_result,\n",
        "            'car_info': car_info\n",
        "        }\n",
        "\n",
        "        return complete_result\n",
        "\n",
        "    def visualize_prediction(self, image_path: str, prediction_result: Dict,\n",
        "                           save_path: str = None):\n",
        "        \"\"\"\n",
        "        Visualize prediction results\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        img = cv2.imread(image_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create figure with subplots\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Original image with prediction\n",
        "        axes[0].imshow(img_rgb)\n",
        "        axes[0].set_title(f\"Predicted: {prediction_result['predicted_damage']}\\n\"\n",
        "                         f\"Confidence: {prediction_result['confidence']:.2f}\\n\"\n",
        "                         f\"Estimated Cost: ${prediction_result['estimated_cost']:.2f}\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Probability distribution\n",
        "        classes = list(prediction_result['class_probabilities'].keys())\n",
        "        probs = list(prediction_result['class_probabilities'].values())\n",
        "\n",
        "        bars = axes[1].bar(range(len(classes)), probs)\n",
        "        axes[1].set_xlabel('Damage Types')\n",
        "        axes[1].set_ylabel('Probability')\n",
        "        axes[1].set_title('Class Probabilities')\n",
        "        axes[1].set_xticks(range(len(classes)))\n",
        "        axes[1].set_xticklabels(classes, rotation=45, ha='right')\n",
        "\n",
        "        # Highlight predicted class\n",
        "        predicted_idx = classes.index(prediction_result['predicted_damage'])\n",
        "        bars[predicted_idx].set_color('red')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    def evaluate_model(self, data_dir: str):\n",
        "        \"\"\"\n",
        "        Evaluate model performance\n",
        "        \"\"\"\n",
        "        # Load test data\n",
        "        image_paths, labels, damage_areas = self.prepare_dataset(data_dir)\n",
        "\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        for img_path, true_label in zip(image_paths, labels):\n",
        "            result = self.predict_damage(img_path)\n",
        "            predictions.append(result['predicted_damage'])\n",
        "            true_labels.append(true_label)\n",
        "\n",
        "        # Print classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(true_labels, predictions))\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        cm = confusion_matrix(true_labels, predictions, labels=self.damage_classes)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.damage_classes,\n",
        "                   yticklabels=self.damage_classes)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, path: str):\n",
        "        \"\"\"\n",
        "        Save the trained model\n",
        "        \"\"\"\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'damage_classes': self.damage_classes,\n",
        "            'label_encoder': self.label_encoder,\n",
        "            'base_prices': self.base_prices\n",
        "        }, path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "    def load_model(self, path: str):\n",
        "        \"\"\"\n",
        "        Load a trained model\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.damage_classes = checkpoint['damage_classes']\n",
        "        self.label_encoder = checkpoint['label_encoder']\n",
        "        self.base_prices = checkpoint['base_prices']\n",
        "        print(f\"Model loaded from {path}\")\n",
        "\n",
        "    def batch_process(self, image_dir: str, output_csv: str = \"damage_predictions.csv\"):\n",
        "        \"\"\"\n",
        "        Process multiple images and save results to CSV\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for img_file in os.listdir(image_dir):\n",
        "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(image_dir, img_file)\n",
        "\n",
        "                try:\n",
        "                    result = self.process_image(img_path)\n",
        "                    results.append({\n",
        "                        'image_name': img_file,\n",
        "                        'damage_type': result['predicted_damage'],\n",
        "                        'confidence': result['confidence'],\n",
        "                        'damage_area': result['predicted_area'],\n",
        "                        'estimated_cost': result['estimated_cost'],\n",
        "                        'cost_lower': result['confidence_interval'][0],\n",
        "                        'cost_upper': result['confidence_interval'][1]\n",
        "                    })\n",
        "                    print(f\"Processed: {img_file}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_file}: {str(e)}\")\n",
        "\n",
        "        # Save results\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "wdDc0o00IQDH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _plot_training_curves(self, train_losses: List, val_losses: List):\n",
        "        \"\"\"\n",
        "        Plot training and validation loss curves\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "def predict_damage(self, image_path: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Predict damage type and area for a single image\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = self.val_transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            cls_output, area_output = self.model(image_tensor)\n",
        "\n",
        "            # Get prediction probabilities\n",
        "            probabilities = torch.softmax(cls_output, dim=1)\n",
        "            confidence, predicted_class = torch.max(probabilities, 1)\n",
        "\n",
        "            # Get damage area prediction\n",
        "            predicted_area = area_output.item()\n",
        "\n",
        "        # Decode prediction\n",
        "        damage_type = self.label_encoder.inverse_transform([predicted_class.item()])[0]\n",
        "        confidence_score = confidence.item()\n",
        "\n",
        "        # Get all class probabilities\n",
        "        all_probabilities = probabilities.cpu().numpy()[0]\n",
        "        class_probabilities = {}\n",
        "        for i, class_name in enumerate(self.damage_classes):\n",
        "            class_probabilities[class_name] = float(all_probabilities[i])\n",
        "\n",
        "        return {\n",
        "            'image_path': image_path,\n",
        "            'predicted_damage': damage_type,\n",
        "            'confidence': confidence_score,\n",
        "            'predicted_area': max(0, min(1, predicted_area)),  # Clamp between 0 and 1\n",
        "            'class_probabilities': class_probabilities\n",
        "        }\n",
        "\n",
        "def estimate_repair_cost(self, prediction_result: Dict,\n",
        "                           car_info: Dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Estimate repair cost based on damage prediction\n",
        "        \"\"\"\n",
        "        damage_type = prediction_result['predicted_damage']\n",
        "        confidence = prediction_result['confidence']\n",
        "        damage_area = prediction_result['predicted_area']\n",
        "\n",
        "        # Base cost\n",
        "        base_cost = self.base_prices.get(damage_type, 0)\n",
        "\n",
        "        # Area multiplier (more damage = higher cost)\n",
        "        area_multiplier = 1 + (damage_area * 2)  # Max 3x multiplier\n",
        "\n",
        "        # Confidence multiplier (lower confidence = higher uncertainty)\n",
        "        confidence_multiplier = 1 + (1 - confidence) * 0.5\n",
        "\n",
        "        # Calculate base repair cost\n",
        "        repair_cost = base_cost * area_multiplier * confidence_multiplier\n",
        "\n",
        "        # Apply car-specific multipliers\n",
        "        if car_info:\n",
        "            # Luxury car multiplier\n",
        "            if car_info.get('luxury_brand', False):\n",
        "                repair_cost *= 1.5\n",
        "\n",
        "            # Age multiplier\n",
        "            age = car_info.get('age', 5)\n",
        "            if age > 10:\n",
        "                repair_cost *= 0.8  # Older cars cheaper to repair\n",
        "            elif age < 3:\n",
        "                repair_cost *= 1.2  # Newer cars more expensive\n",
        "\n",
        "            # Car value multiplier\n",
        "            car_value = car_info.get('value', 15000)\n",
        "            if car_value > 30000:\n",
        "                repair_cost *= 1.3\n",
        "            elif car_value < 10000:\n",
        "                repair_cost *= 0.7\n",
        "\n",
        "        # Calculate confidence interval\n",
        "        uncertainty = 1 - confidence\n",
        "        lower_bound = repair_cost * (1 - uncertainty * 0.3)\n",
        "        upper_bound = repair_cost * (1 + uncertainty * 0.3)\n",
        "\n",
        "        return {\n",
        "            'estimated_cost': float(repair_cost),\n",
        "            'confidence_interval': (float(lower_bound), float(upper_bound)),\n",
        "            'cost_factors': {\n",
        "                'base_cost': float(base_cost),\n",
        "                'area_multiplier': float(area_multiplier),\n",
        "                'confidence_multiplier': float(confidence_multiplier),\n",
        "                'damage_area': float(damage_area)\n",
        "            }\n",
        "        }\n",
        "\n",
        "def process_image(self, image_path: str, car_info: Dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Complete pipeline: predict damage and estimate cost\n",
        "        \"\"\"\n",
        "        # Predict damage\n",
        "        damage_result = self.predict_damage(image_path)\n",
        "\n",
        "        # Estimate cost\n",
        "        cost_result = self.estimate_repair_cost(damage_result, car_info)\n",
        "\n",
        "        # Combine results\n",
        "        complete_result = {\n",
        "            **damage_result,\n",
        "            **cost_result,\n",
        "            'car_info': car_info\n",
        "        }\n",
        "\n",
        "        return complete_result\n",
        "\n",
        "def visualize_prediction(self, image_path: str, prediction_result: Dict,\n",
        "                           save_path: str = None):\n",
        "        \"\"\"\n",
        "        Visualize prediction results\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        img = cv2.imread(image_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create figure with subplots\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Original image with prediction\n",
        "        axes[0].imshow(img_rgb)\n",
        "        axes[0].set_title(f\"Predicted: {prediction_result['predicted_damage']}\\n\"\n",
        "                         f\"Confidence: {prediction_result['confidence']:.2f}\\n\"\n",
        "                         f\"Estimated Cost: ${prediction_result['estimated_cost']:.2f}\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Probability distribution\n",
        "        classes = list(prediction_result['class_probabilities'].keys())\n",
        "        probs = list(prediction_result['class_probabilities'].values())\n",
        "\n",
        "        bars = axes[1].bar(range(len(classes)), probs)\n",
        "        axes[1].set_xlabel('Damage Types')\n",
        "        axes[1].set_ylabel('Probability')\n",
        "        axes[1].set_title('Class Probabilities')\n",
        "        axes[1].set_xticks(range(len(classes)))\n",
        "        axes[1].set_xticklabels(classes, rotation=45, ha='right')\n",
        "\n",
        "        # Highlight predicted class\n",
        "        predicted_idx = classes.index(prediction_result['predicted_damage'])\n",
        "        bars[predicted_idx].set_color('red')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "def evaluate_model(self, data_dir: str):\n",
        "        \"\"\"\n",
        "        Evaluate model performance\n",
        "        \"\"\"\n",
        "        # Load test data\n",
        "        image_paths, labels, damage_areas = self.prepare_dataset(data_dir)\n",
        "\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        for img_path, true_label in zip(image_paths, labels):\n",
        "            result = self.predict_damage(img_path)\n",
        "            predictions.append(result['predicted_damage'])\n",
        "            true_labels.append(true_label)\n",
        "\n",
        "        # Print classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(true_labels, predictions))\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        cm = confusion_matrix(true_labels, predictions, labels=self.damage_classes)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.damage_classes,\n",
        "                   yticklabels=self.damage_classes)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "def save_model(self, path: str):\n",
        "        \"\"\"\n",
        "        Save the trained model\n",
        "        \"\"\"\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'damage_classes': self.damage_classes,\n",
        "            'label_encoder': self.label_encoder,\n",
        "            'base_prices': self.base_prices\n",
        "        }, path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "def load_model(self, path: str):\n",
        "        \"\"\"\n",
        "        Load a trained model\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.damage_classes = checkpoint['damage_classes']\n",
        "        self.label_encoder = checkpoint['label_encoder']\n",
        "        self.base_prices = checkpoint['base_prices']\n",
        "        print(f\"Model loaded from {path}\")\n",
        "\n",
        "def batch_process(self, image_dir: str, output_csv: str = \"damage_predictions.csv\"):\n",
        "        \"\"\"\n",
        "        Process multiple images and save results to CSV\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for img_file in os.listdir(image_dir):\n",
        "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(image_dir, img_file)\n",
        "\n",
        "                try:\n",
        "                    result = self.process_image(img_path)\n",
        "                    results.append({\n",
        "                        'image_name': img_file,\n",
        "                        'damage_type': result['predicted_damage'],\n",
        "                        'confidence': result['confidence'],\n",
        "                        'damage_area': result['predicted_area'],\n",
        "                        'estimated_cost': result['estimated_cost'],\n",
        "                        'cost_lower': result['confidence_interval'][0],\n",
        "                        'cost_upper': result['confidence_interval'][1]\n",
        "                    })\n",
        "                    print(f\"Processed: {img_file}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_file}: {str(e)}\")\n",
        "\n",
        "        # Save results\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "Hih29cAtIYo6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize detector\n",
        "    detector = CarDamageDetector()\n",
        "\n",
        "\n",
        "    print(\"Starting training with your 70-image dataset...\")\n",
        "    detector.train_model(\n",
        "        data_dir='/content/drive/MyDrive/cd_datset',  # Your dataset directory\n",
        "        epochs=50,  # Increased epochs for small dataset\n",
        "        batch_size=4,  # Small batch size for small dataset\n",
        "        learning_rate=0.0001  # Lower learning rate for fine-tuning\n",
        "    )\n",
        "\n",
        "    # Example: Process a single image\n",
        "    image_path = \"path/to/your/test/image.jpg\"\n",
        "    car_info = {\n",
        "        'age': 5,\n",
        "        'value': 20000,\n",
        "        'luxury_brand': False\n",
        "    }\n",
        "\n",
        "    result = detector.process_image(image_path, car_info)\n",
        "\n",
        "    print(f\"\\nDamage Detection Results:\")\n",
        "    print(f\"Predicted damage: {result['predicted_damage']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.2f}\")\n",
        "    print(f\"Damage area: {result['predicted_area']:.2f}\")\n",
        "    print(f\"Estimated repair cost: ${result['estimated_cost']:.2f}\")\n",
        "    print(f\"Cost range: ${result['confidence_interval'][0]:.2f} - ${result['confidence_interval'][1]:.2f}\")\n",
        "\n",
        "    # Visualize result\n",
        "    detector.visualize_prediction(image_path, result, \"prediction_result.png\")\n",
        "\n",
        "    # Batch processing\n",
        "    # detector.batch_process(\"test_images\", \"results.csv\")\n",
        "\n",
        "    print(\"\\nTraining completed! Your CNN model is ready for car damage detection.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "jO0KMnb6IihI",
        "outputId": "a5f3c1fa-2535-42ee-be65-db34e3c7b557"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Starting training with your 70-image dataset...\n",
            "Warning: /content/drive/MyDrive/cd_datset/labels.csv is empty or has no columns.\n",
            "Found 0 images\n",
            "Label distribution: Counter()\n",
            "No images found or labeled. Cannot proceed with training.\n",
            "\n",
            "Damage Detection Results:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-1767452892.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-20-1767452892.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nDamage Detection Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted damage: {result['predicted_damage']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Confidence: {result['confidence']:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Damage area: {result['predicted_area']:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7A0qvXD9FlaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}